{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba604d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73fd9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "from util.data_parser import parse_data\n",
    "from util.model_utils import test_model, model_load\n",
    "from util.utility import find_gpu, Logger\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a8e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset DATASET]\n",
      "                             [--batch_size BATCH_SIZE]\n",
      "                             [--model_type MODEL_TYPE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/home/linfeng/.local/share/jupyter/runtime/kernel-v2-10158658WxOFeWPoqfr.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linfeng/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# 使用argparse处理命令行参数\n",
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "# dataset，默认值为'cifar10'\n",
    "parser.add_argument('--dataset', type = str, default = 'cifar10', help = 'The dataset used, default = \"cifar10\".')\n",
    "# batch_size，用于指定批量大小\n",
    "parser.add_argument('--batch_size', type = int, default = 128, help = 'The batch size, default is 128.')\n",
    "# model_type，用于指定模型类型\n",
    "parser.add_argument('--model_type', type = str, default = 'resnet18', help = 'The type of the model, default is \"resnet18\".')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f513f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0eb72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设备选择\n",
    "device = torch.device(f\"cuda:{find_gpu()}\" if torch.cuda.is_available() and find_gpu() is not None else \"cpu\")\n",
    "print(f\"Using {device}.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545aa5a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 初始化日志和保存目录\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m save_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoint1/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m log_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogger.log\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "# 初始化日志和保存目录\n",
    "save_folder = f'./checkpoint1/{args.dataset}/{args.model_type}/'\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "log_path = os.path.join(save_folder, 'logger.log')\n",
    "logger = Logger(log_path=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5a172a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50000 instances are picked from the training set\n"
     ]
    }
   ],
   "source": [
    "# 假设你的数据加载函数可以这样调用（确保使用与训练时相同的参数）\n",
    "_, _, testloader, _ = parse_data(name=args.dataset, batch_size=args.batch_size, valid_ratio=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d03fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DataNormalizeLayer()\n",
       "  (1): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_load(dataset=args.dataset, model_type=args.model_type, model_path='./checkpoint', normalize=None)\n",
    "model = model.to(device)\n",
    "model.eval()  # 设置为评估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e002509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "\n",
    "def fgsm_attack(model, image, label, epsilon):\n",
    "    # 设置损失函数\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # 激活图像的梯度属性\n",
    "    image.requires_grad = True\n",
    "\n",
    "    # 正向传播和损失计算\n",
    "    output = model(image)\n",
    "    model.zero_grad()\n",
    "    loss = criterion(output, label)\n",
    "    loss.backward()\n",
    "\n",
    "    # 生成扰动图像\n",
    "    image_grad = image.grad.data\n",
    "    perturbed_image = image + epsilon * image_grad.sign()\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)  # 保持数据在正常范围内\n",
    "\n",
    "    # 日志记录\n",
    "    logging.info(f'FGSM Attack - Loss: {loss.item()}')\n",
    "\n",
    "    return perturbed_image\n",
    "\n",
    "\n",
    "def pgd_attack(model, images, labels, eps, alpha, iters=40):\n",
    "    # 定义损失函数\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    original_images = images.data.clone()\n",
    "\n",
    "    for i in range(iters):\n",
    "        images.requires_grad = True\n",
    "        outputs = model(images)\n",
    "        model.zero_grad()\n",
    "        cost = criterion(outputs, labels)\n",
    "        cost.backward()\n",
    "\n",
    "        # 更新扰动图像\n",
    "        images = images + alpha * images.grad.sign()\n",
    "        # 保持扰动大小在 eps 范围内\n",
    "        eta = torch.clamp(images - original_images, min=-eps, max=eps)\n",
    "        images = torch.clamp(original_images + eta, 0, 1).detach_()\n",
    "\n",
    "        # 日志记录\n",
    "        logging.info(f'PGD Attack - Iteration {i+1}/{iters}, Loss: {cost.item()}')\n",
    "\n",
    "    return images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the attacked network on the 10000 test images: 13 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "epsilon = 0.03  # FGSM 的扰动大小\n",
    "\n",
    "for images, labels in testloader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    images.requires_grad = True\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # FGSM 攻击\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    perturbed_data = fgsm_attack(images, epsilon, images.grad)\n",
    "\n",
    "    # PGD 攻击\n",
    "    # perturbed_data = pgd_attack(model, images, labels, eps=0.03, alpha=0.01, iters=40)\n",
    "\n",
    "    outputs = model(perturbed_data)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the attacked network on the 10000 test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a988e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb8794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf99874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ad2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1398007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27a539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsvd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
